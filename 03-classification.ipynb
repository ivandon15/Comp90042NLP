{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the corpus we will be using, which is included in NLTK. You will need NLTK and Scikit-learn (as well as their dependencies, in particular scipy and numpy) to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading reuters: <urlopen error [WinError 10054]\n",
      "[nltk_data]     远程主机强迫关闭了一个现有的连接。>\n"
     ]
    }
   ],
   "source": [
    "# https://www.nltk.org/book/ch02.html\n",
    "import nltk\n",
    "nltk.download(\"reuters\") # if necessary\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# reuters 总共分了 90 个 topics，然后数据集分了train和test两个，所以查询fileids会有test/1425...\n",
    "# 每一个fileid就是一个文章（或者说数据集），可以通过reuters.fileid(category)来查找这个topic下有哪些文章，\n",
    "# 可以通过reuters.category(fileid)来查询这个文章属于什么topic\n",
    "# 可以通过reuters.words(categories='barley')来查询制定BOW内容，比如这个就给出'barley'类别下的bow有哪些\n",
    "# 但reuter有意思的是一篇新闻中往往会有多个主题，所以可能同一片新闻会出现在多个topic下\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK sample of the Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and is divided into a training and test sets, a split which we will preserve here. Let's look at the counts of texts the various categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acq 2369\n",
      "alum 58\n",
      "barley 51\n",
      "bop 105\n",
      "carcass 68\n",
      "castor-oil 2\n",
      "cocoa 73\n",
      "coconut 6\n",
      "coconut-oil 7\n",
      "coffee 139\n",
      "copper 65\n",
      "copra-cake 3\n",
      "corn 237\n",
      "cotton 59\n",
      "cotton-oil 3\n",
      "cpi 97\n",
      "cpu 4\n",
      "crude 578\n",
      "dfl 3\n",
      "dlr 175\n",
      "dmk 14\n",
      "earn 3964\n",
      "fuel 23\n",
      "gas 54\n",
      "gnp 136\n",
      "gold 124\n",
      "grain 582\n",
      "groundnut 9\n",
      "groundnut-oil 2\n",
      "heat 19\n",
      "hog 22\n",
      "housing 20\n",
      "income 16\n",
      "instal-debt 6\n",
      "interest 478\n",
      "ipi 53\n",
      "iron-steel 54\n",
      "jet 5\n",
      "jobs 67\n",
      "l-cattle 8\n",
      "lead 29\n",
      "lei 15\n",
      "lin-oil 2\n",
      "livestock 99\n",
      "lumber 16\n",
      "meal-feed 49\n",
      "money-fx 717\n",
      "money-supply 174\n",
      "naphtha 6\n",
      "nat-gas 105\n",
      "nickel 9\n",
      "nkr 3\n",
      "nzdlr 4\n",
      "oat 14\n",
      "oilseed 171\n",
      "orange 27\n",
      "palladium 3\n",
      "palm-oil 40\n",
      "palmkernel 3\n",
      "pet-chem 32\n",
      "platinum 12\n",
      "potato 6\n",
      "propane 6\n",
      "rand 3\n",
      "rape-oil 8\n",
      "rapeseed 27\n",
      "reserves 73\n",
      "retail 25\n",
      "rice 59\n",
      "rubber 49\n",
      "rye 2\n",
      "ship 286\n",
      "silver 29\n",
      "sorghum 34\n",
      "soy-meal 26\n",
      "soy-oil 25\n",
      "soybean 111\n",
      "strategic-metal 27\n",
      "sugar 162\n",
      "sun-meal 2\n",
      "sun-oil 7\n",
      "sunseed 16\n",
      "tea 13\n",
      "tin 30\n",
      "trade 485\n",
      "veg-oil 124\n",
      "wheat 283\n",
      "wpi 29\n",
      "yen 59\n",
      "zinc 34\n"
     ]
    }
   ],
   "source": [
    "for category in reuters.categories():\n",
    "#     print(reuters.fileids(category))\n",
    "    # 这个意思就是这个类别下有多少文章\n",
    "    print (category, len(reuters.fileids(category)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the documents in the corpus are tagged with multiple labels; in this situation, a straightforward approach is to build a classifier for each label. Let's build a classifier to distinguish the most common topic in the corpus, \"acq\" (acqusitions). First, here's some code to build the dataset in preparation for classification using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def get_BOW(text):\n",
    "    # 先得到一个文本的词袋，即这个文本中每个词的词频\n",
    "    BOW = {}\n",
    "    # 通常这里会用stemm或者lemma来统计，但这里没有\n",
    "    for word in text:\n",
    "        BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW\n",
    "\n",
    "# 根据topic来找数据，并存下每个数据的bow，用于后期来预测某一个text是acq还是不是acq，做一个二值分类\n",
    "def prepare_reuters_data(topic,feature_extractor):\n",
    "    training_set = []\n",
    "    training_classifications = []\n",
    "    test_set = []\n",
    "    test_classifications = []\n",
    "    \n",
    "    # 遍历所有数据集file，里面有train 有test\n",
    "    for file_id in reuters.fileids():\n",
    "        # 得到这个数据集下的bow\n",
    "        feature_dict = feature_extractor(reuters.words(file_id))   \n",
    "        if file_id.startswith(\"train\"):\n",
    "            # 有多少train文件就有多少元素，每个元素是一个bow\n",
    "            training_set.append(feature_dict)\n",
    "            \n",
    "            # 看看这个数据属不属于topic，标注是和不是\n",
    "            if topic in reuters.categories(file_id):\n",
    "                training_classifications.append(topic)\n",
    "            else:\n",
    "                training_classifications.append(\"not \" + topic)\n",
    "        else:\n",
    "            # 区分测试集\n",
    "            test_set.append(feature_dict)\n",
    "            if topic in reuters.categories(file_id):\n",
    "                test_classifications.append(topic)\n",
    "            else:\n",
    "                test_classifications.append(\"not \" + topic)     \n",
    "    # 向量化，所有bow的长度为向量的长度，text中有这个词出现则为1，没有则为0，整个训练集是一个很稀疏的矩阵。\n",
    "    vectorizer = DictVectorizer()\n",
    "    # 保证训练集和测试集的向量长度相同，主要是通过忽略那些没有在training data中出现却在test中出现的单词。\n",
    "    training_data = vectorizer.fit_transform(training_set)\n",
    "    test_data = vectorizer.transform(test_set)\n",
    "    return training_data,training_classifications,test_data,test_classifications\n",
    "\n",
    "trn_data,trn_classes,test_data,test_classes = prepare_reuters_data(\"acq\",get_BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code builds a sparse bag of words feature representation (a Python dictionary) for each text in the corpus (which is pre-tokenized), and places it to the appropriate list depending on whether it is testing or training; a corresponding list of correct classifications is created at the same time. The scikit-learn DictVectorizer class converts Python dictionaries into the scipy sparse matrices which Scikit-learn uses; for the training set, use the fit_transform method (which fixes the total number of features in the model), and for the test set, use transform method (which ignores any features in the test set that weren't in the training set). Next, let's prepare some classifiers to test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfs = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "        MultinomialNB(),LinearSVC(),LogisticRegression()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we are using default settings for all these classifiers. Let's start by doing 10-fold cross validation on the training set, and looking at the accuracy, recall, precision, and f1-score for each (be patient, this may take a while to complete)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "accuracy\n",
      "0.9258591839361565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.85      0.79      0.82      1650\n",
      "     not acq       0.95      0.96      0.95      6119\n",
      "\n",
      "    accuracy                           0.93      7769\n",
      "   macro avg       0.90      0.88      0.89      7769\n",
      "weighted avg       0.92      0.93      0.92      7769\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "accuracy\n",
      "0.936542669584245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.86      0.84      0.85      1650\n",
      "     not acq       0.96      0.96      0.96      6119\n",
      "\n",
      "    accuracy                           0.94      7769\n",
      "   macro avg       0.91      0.90      0.90      7769\n",
      "weighted avg       0.94      0.94      0.94      7769\n",
      "\n",
      "RandomForestClassifier()\n",
      "accuracy\n",
      "0.9639593255245206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.94      0.89      0.91      1650\n",
      "     not acq       0.97      0.99      0.98      6119\n",
      "\n",
      "    accuracy                           0.96      7769\n",
      "   macro avg       0.96      0.94      0.94      7769\n",
      "weighted avg       0.96      0.96      0.96      7769\n",
      "\n",
      "MultinomialNB()\n",
      "accuracy\n",
      "0.9549491569056506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.84      0.98      0.90      1650\n",
      "     not acq       0.99      0.95      0.97      6119\n",
      "\n",
      "    accuracy                           0.95      7769\n",
      "   macro avg       0.92      0.96      0.94      7769\n",
      "weighted avg       0.96      0.95      0.96      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n",
      "accuracy\n",
      "0.9769597116746042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.95      0.94      0.95      1650\n",
      "     not acq       0.98      0.99      0.99      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.96      0.97      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "accuracy\n",
      "0.9763161282018278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.95      0.94      0.94      1650\n",
      "     not acq       0.98      0.99      0.98      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.96      0.96      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 普通的validation：将数据等类别比例的拆分成train和test，但这个会造成每次train和test数据不同，可能造成结果有偏差\n",
    "# loocv，遍历整个数据，每次就留下一个作为test，其他都是train，但这样会很慢\n",
    "# k-fold cv，把数据先分成k份，遍历k次，每次用其中一份作为test，剩下的k-1作为trian\n",
    "\n",
    "# 关于k-fold的一些内容\n",
    "\"\"\"\n",
    "1、在训练模型时，如果已经预先指定好超参数了，这时候k交叉验证训练出来的模型只是不同数据训练出来的参数(权重)不同的相同结构的模型。\n",
    "一些文章中预先指定了超参数，再用k交叉验证只能单单说明在这组超参数下，模型的准确率是这样的，并不能说明当下的这组超参数是比其他的好。\n",
    "2、k交叉验证的用法是分别对自己想要尝试的n组超参数进行k交叉验证训练模型，然后比较n组超参数下用k交叉验证方法得到的n个平均误差，然后选出误差较小的那组超参数。\n",
    "3、在做实验时，比如要比较不同学习算法的效果，要先分别对不同算法用k交叉验证方法确定一组较好的超参数，然后在测试集上比较他们的准确率\n",
    "\"\"\"\n",
    "# 简而言之就是用我给model的一组超参数，在不停变化的数据集上（不同的train、test组合方法）进行验证，每一次预测完都会有一个结果，然后对这些结果的值进行平均。\n",
    "# 然后看这个平均值怎么样，如果好的话说明我的超参选的好。\n",
    "def do_multiple_10foldcrossvalidation(clfs,data,classifications):\n",
    "    for clf in clfs:\n",
    "        predictions = model_selection.cross_val_predict(clf, data,classifications, cv=10)\n",
    "        print (clf)\n",
    "        print (\"accuracy\")\n",
    "        # 准确率是原数据的和预测的\n",
    "        print (accuracy_score(classifications,predictions))\n",
    "        print (classification_report(classifications,predictions))\n",
    "        \n",
    "do_multiple_10foldcrossvalidation(clfs,trn_data,trn_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the classifiers are not obviously biased towards a particular task, so accuracy and f-score are nearly the same. The numbers are generally quite high, indicating that it is a fairly easy classification task. In terms of the best classifier, the clear standouts here are the SVM and Logistic Regression classifiers, while <i>k</i>NN is clearly the worst. One reason <i>k</i>NN might be doing poorly is that it is particularly susceptible to a noisy feature space with dimensions that are irrelevant to the task（它特别容易受到具有与任务无关的维度的噪声特征空间的影响。）. Let's try to improve performance by removing stopwords and doing lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10054]\n",
      "[nltk_data]     远程主机强迫关闭了一个现有的连接。>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "accuracy\n",
      "0.9387308533916849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.90      0.80      0.85      1650\n",
      "     not acq       0.95      0.98      0.96      6119\n",
      "\n",
      "    accuracy                           0.94      7769\n",
      "   macro avg       0.92      0.89      0.90      7769\n",
      "weighted avg       0.94      0.94      0.94      7769\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "accuracy\n",
      "0.9423349208392329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.87      0.86      0.86      1650\n",
      "     not acq       0.96      0.96      0.96      6119\n",
      "\n",
      "    accuracy                           0.94      7769\n",
      "   macro avg       0.91      0.91      0.91      7769\n",
      "weighted avg       0.94      0.94      0.94      7769\n",
      "\n",
      "RandomForestClassifier()\n",
      "accuracy\n",
      "0.9657613592482945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.94      0.90      0.92      1650\n",
      "     not acq       0.97      0.98      0.98      6119\n",
      "\n",
      "    accuracy                           0.97      7769\n",
      "   macro avg       0.96      0.94      0.95      7769\n",
      "weighted avg       0.97      0.97      0.97      7769\n",
      "\n",
      "MultinomialNB()\n",
      "accuracy\n",
      "0.9561076071566482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.84      0.98      0.90      1650\n",
      "     not acq       0.99      0.95      0.97      6119\n",
      "\n",
      "    accuracy                           0.96      7769\n",
      "   macro avg       0.92      0.96      0.94      7769\n",
      "weighted avg       0.96      0.96      0.96      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n",
      "accuracy\n",
      "0.9788904620929334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.95      0.95      0.95      1650\n",
      "     not acq       0.99      0.99      0.99      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.97      0.97      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "accuracy\n",
      "0.9792766121765993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.96      0.95      0.95      1650\n",
      "     not acq       0.99      0.99      0.99      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.97      0.97      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def get_BOW_lowered_no_stopwords(text):\n",
    "    # 通常这个在一开始bow那边就要做的，把字母lower，避免大小字母还分不同单词。去除停用词\n",
    "    BOW = {}\n",
    "    for word in text:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords:\n",
    "            BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW\n",
    "\n",
    "trn_data,trn_classes,test_data,test_classes = prepare_reuters_data(\"acq\",get_BOW_lowered_no_stopwords)\n",
    "\n",
    "do_multiple_10foldcrossvalidation(clfs,trn_data,trn_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did improve the performance of <i>k</i>NN by about 1% accuracy, but it is still the worst classifier. Gains for other classifiers were more modest, since the scores were already high, and those classifiers are more robust to feature noise.\n",
    "\n",
    "The random forest classifier is doing worse than its reputation would suggest. The default number of decision trees (n_estimators) used in the model is only 10, which is fairly low: lets see if we can find a better number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=10)\n",
      "accuracy\n",
      "0.9558501737675377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.89      0.90      0.90      1650\n",
      "     not acq       0.97      0.97      0.97      6119\n",
      "\n",
      "    accuracy                           0.96      7769\n",
      "   macro avg       0.93      0.94      0.93      7769\n",
      "weighted avg       0.96      0.96      0.96      7769\n",
      "\n",
      "RandomForestClassifier(n_estimators=50)\n",
      "accuracy\n",
      "0.965503925859184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.93      0.91      0.92      1650\n",
      "     not acq       0.97      0.98      0.98      6119\n",
      "\n",
      "    accuracy                           0.97      7769\n",
      "   macro avg       0.95      0.94      0.95      7769\n",
      "weighted avg       0.97      0.97      0.97      7769\n",
      "\n",
      "RandomForestClassifier()\n",
      "accuracy\n",
      "0.9679495430557343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.94      0.91      0.92      1650\n",
      "     not acq       0.97      0.98      0.98      6119\n",
      "\n",
      "    accuracy                           0.97      7769\n",
      "   macro avg       0.96      0.95      0.95      7769\n",
      "weighted avg       0.97      0.97      0.97      7769\n",
      "\n",
      "RandomForestClassifier(n_estimators=150)\n",
      "accuracy\n",
      "0.9675633929720685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.94      0.91      0.92      1650\n",
      "     not acq       0.98      0.98      0.98      6119\n",
      "\n",
      "    accuracy                           0.97      7769\n",
      "   macro avg       0.96      0.95      0.95      7769\n",
      "weighted avg       0.97      0.97      0.97      7769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_to_test = [10,50,100,150]\n",
    "# ？？？？还真的可以这样吗，一口气生成这么多超参不同的clf\n",
    "rfs = [RandomForestClassifier(n_estimators=n) for n in n_to_test]\n",
    "do_multiple_10foldcrossvalidation(rfs,trn_data,trn_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, more subclassifiers improved things, though the Random Forest classifier is still slightly inferior to the SVM and Logistic Regression classifiers in this BOW (i.e. large feature set) situation. \n",
    "\n",
    "Both SVM and Logistic Regression classifiers have a C parameter which controls the degree of regularization (lower C means more emphasis on regularization when optimising the model). Let's see if we can improve the performance of the Logistic Regression classifier by changing the C parameter from the default (1.0). For this parameter, a logrithmic scale is appropriate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.001)\n",
      "accuracy\n",
      "0.9298494014673703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.93      0.72      0.81      1650\n",
      "     not acq       0.93      0.99      0.96      6119\n",
      "\n",
      "    accuracy                           0.93      7769\n",
      "   macro avg       0.93      0.85      0.89      7769\n",
      "weighted avg       0.93      0.93      0.93      7769\n",
      "\n",
      "LogisticRegression(C=0.01)\n",
      "accuracy\n",
      "0.9670485261938473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.94      0.90      0.92      1650\n",
      "     not acq       0.97      0.99      0.98      6119\n",
      "\n",
      "    accuracy                           0.97      7769\n",
      "   macro avg       0.96      0.94      0.95      7769\n",
      "weighted avg       0.97      0.97      0.97      7769\n",
      "\n",
      "LogisticRegression(C=0.1)\n",
      "accuracy\n",
      "0.9765735615909383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.95      0.94      0.94      1650\n",
      "     not acq       0.98      0.99      0.99      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.96      0.96      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1)\n",
      "accuracy\n",
      "0.9792766121765993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.96      0.95      0.95      1650\n",
      "     not acq       0.99      0.99      0.99      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.97      0.97      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10)\n",
      "accuracy\n",
      "0.9794053288711546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.96      0.95      0.95      1650\n",
      "     not acq       0.99      0.99      0.99      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.97      0.97      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100)\n",
      "accuracy\n",
      "0.9792766121765993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.95      0.95      0.95      1650\n",
      "     not acq       0.99      0.99      0.99      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.97      0.97      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000)\n",
      "accuracy\n",
      "0.9796627622602652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.96      0.95      0.95      1650\n",
      "     not acq       0.99      0.99      0.99      6119\n",
      "\n",
      "    accuracy                           0.98      7769\n",
      "   macro avg       0.97      0.97      0.97      7769\n",
      "weighted avg       0.98      0.98      0.98      7769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "c_to_test = [0.001,0.01,0.1,1,10,100, 1000]\n",
    "lrcs = [LogisticRegression(C=c) for c in c_to_test]\n",
    "do_multiple_10foldcrossvalidation(lrcs,trn_data,trn_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, changing the parameter from the default is not desirable. When training with fairly large datasets to solve a straightforward task with a simple classifier, the effect of regularization is often minimal.\n",
    "\n",
    "Under normal circumstances we might do more parameter tuning or feature selection (and we encourage you to play around), but let's just skip to testing the classifiers on the test set and displaying the results using matplotlib...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9304405432262338, 0.9380589599205035, 0.9748261013580656, 0.9738323948327261, 0.9817820470354423, 0.9834382245776747]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Develop\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_and_graph(clfs,training_data,training_classifications,test_data,test_classifications):\n",
    "    accuracies = []\n",
    "    for clf in clfs:\n",
    "        clf.fit(training_data,training_classifications)\n",
    "        predictions = clf.predict(test_data)\n",
    "        accuracies.append(accuracy_score(test_classifications,predictions))\n",
    "    print (accuracies)\n",
    "    p = plt.bar([num + 0.25 for num in range(len(clfs))], accuracies,0.5)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy classifying acq topic in Reuters, by classifier')\n",
    "    plt.ylim([0.9,1])\n",
    "    plt.xticks([num + 0.5 for num in range(len(clfs))], ('kNN', 'DT', 'RF', 'NB', 'SVM', 'LR'))\n",
    "    plt.show()\n",
    "\n",
    "test_and_graph(clfs,trn_data,trn_classes,test_data,test_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are pretty close to what we saw using cross-validation, with Logistic Regression winning out over SVMs by a tiny margin, with an impressive accuracy of 98.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
